{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import one_hot, scatter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import GCNConv, NNConv\n",
    "from torch_geometric.nn.conv import GATv2Conv, GATConv, TransformerConv\n",
    "from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdchem import BondType, HybridizationType\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeNet(name=\"lipo\", root=\"MoleculeNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_N(torch.nn.Module):\n",
    "    def __init__(self, layer:int, dim=32, dataset=dataset):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "        self.dataset = dataset\n",
    "        self.dim = dim\n",
    "        self.conv1 = GCNConv(self.dataset.num_node_features, self.dim, improved=True)\n",
    "        self.convn = GCNConv(self.dim, self.dim, improved=True)\n",
    "        self.out = pyg.nn.Linear(self.dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, batch, edge_index, edge_attr = data.x, data.batch, data.edge_index, data.edge_attr\n",
    "        x = x.to(torch.float)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        for i in range(2, self.layer + 1):\n",
    "            x = self.convn(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = pyg.nn.global_add_pool(x, batch) \n",
    "        #x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの分割(total: 130831)\n",
    "num_train, num_val = int(len(dataset)*0.6), int(len(dataset)*0.2)\n",
    "num_test = len(dataset) - (num_train + num_val)\n",
    "batch_size = 32\n",
    "\n",
    "# 乱数の固定\n",
    "device = torch.device(\"cpu\")\n",
    "seed = 0\n",
    "pyg.seed_everything(seed=seed)\n",
    "train_set, valid_set, test_set = random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "#Dataloaderの生成\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, worker_init_fn=pyg.seed_everything(seed))\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, worker_init_fn=pyg.seed_everything(seed))\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, worker_init_fn=pyg.seed_everything(seed))\n",
    "\n",
    "layer = 3\n",
    "dim = 32\n",
    "model = GCN_N(layer=layer,dim=dim)\n",
    "# 損失関数\n",
    "criterion = F.mse_loss\n",
    "# Optimizerの初期化\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 53., 112., 162., 327., 447., 688., 762., 911., 528., 210.]),\n",
       " array([-1.5, -0.9, -0.3,  0.3,  0.9,  1.5,  2.1,  2.7,  3.3,  3.9,  4.5]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [i.item() for i in dataset.y]\n",
    "plt.hist(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss:0.984069940973217, valid_loss:1.0330747201280532\n",
      "Epoch 2 | train_loss:0.9896199545966121, valid_loss:1.0141647905534206\n",
      "Epoch 3 | train_loss:0.98577363008561, valid_loss:1.013377153393055\n",
      "Epoch 4 | train_loss:0.984529713978718, valid_loss:1.0261124555821868\n",
      "Epoch 5 | train_loss:0.979943129318999, valid_loss:1.0334977358436948\n",
      "Epoch 6 | train_loss:0.9861215325587892, valid_loss:1.018725092045331\n",
      "Epoch 7 | train_loss:0.984322895083636, valid_loss:1.0375830428147808\n",
      "Epoch 8 | train_loss:0.9693014976607417, valid_loss:1.0063442056249752\n",
      "Epoch 9 | train_loss:0.9890587902386656, valid_loss:1.0196995266765754\n",
      "Epoch 10 | train_loss:0.9818051062417332, valid_loss:1.0010953099113646\n",
      "Epoch 11 | train_loss:0.9728077781171853, valid_loss:1.0268936159546376\n",
      "Epoch 12 | train_loss:1.0668915900738016, valid_loss:1.025257452065658\n",
      "Epoch 13 | train_loss:0.9766882038577094, valid_loss:1.0383499940481553\n",
      "Epoch 14 | train_loss:0.9742696371267079, valid_loss:1.0186766161380045\n",
      "Epoch 15 | train_loss:1.0043966830258786, valid_loss:1.0334953093137698\n",
      "Epoch 16 | train_loss:0.9815106514598795, valid_loss:1.0273620159038663\n",
      "Epoch 17 | train_loss:0.9706390433935803, valid_loss:1.1846654973171309\n",
      "Epoch 18 | train_loss:0.9752088005747945, valid_loss:1.0323616034935978\n",
      "Epoch 19 | train_loss:1.0047583192658378, valid_loss:1.0967390407263684\n",
      "Epoch 20 | train_loss:0.9930150664163584, valid_loss:1.0154608384618808\n",
      "Epoch 21 | train_loss:0.970346033268046, valid_loss:1.0362297958434525\n",
      "Epoch 22 | train_loss:0.9692011986132416, valid_loss:1.0117455687173833\n",
      "Epoch 23 | train_loss:0.9720824387807866, valid_loss:1.0649288316089525\n",
      "Epoch 24 | train_loss:1.0029844615833392, valid_loss:1.0220970907942906\n",
      "Epoch 25 | train_loss:0.9808249990501792, valid_loss:1.0402805791516365\n",
      "Epoch 26 | train_loss:1.006261881216732, valid_loss:1.1113176435341185\n",
      "Epoch 27 | train_loss:0.9833828768760728, valid_loss:1.067288595880178\n",
      "Epoch 28 | train_loss:0.9857951377303193, valid_loss:1.0090587838445346\n",
      "Epoch 29 | train_loss:0.995941576928847, valid_loss:1.0181939015158448\n",
      "Epoch 30 | train_loss:1.0099732323540669, valid_loss:1.0381324076891685\n",
      "Epoch 31 | train_loss:0.9710999775897625, valid_loss:0.993160386024699\n",
      "Epoch 32 | train_loss:0.9815994042752485, valid_loss:1.033243445747624\n",
      "Epoch 33 | train_loss:0.9868589111625705, valid_loss:1.0063391426394408\n",
      "Epoch 34 | train_loss:1.0189253663833364, valid_loss:1.035771707994138\n",
      "Epoch 35 | train_loss:0.9826555838797119, valid_loss:1.019771435582068\n",
      "Epoch 36 | train_loss:0.9813936645747988, valid_loss:1.0113786125347863\n",
      "Epoch 37 | train_loss:0.9603562229592072, valid_loss:0.997937032659449\n",
      "Epoch 38 | train_loss:0.9554054388838711, valid_loss:0.9956411725620067\n",
      "Epoch 39 | train_loss:0.9630059865546361, valid_loss:1.0020472572046948\n",
      "Epoch 40 | train_loss:0.999539303513807, valid_loss:1.1526972954523775\n",
      "Epoch 41 | train_loss:1.0228653714001101, valid_loss:1.039789686318949\n",
      "Epoch 42 | train_loss:0.9731740953286138, valid_loss:1.0282260988071388\n",
      "Epoch 43 | train_loss:0.9822521069272278, valid_loss:1.0071775970338612\n",
      "Epoch 44 | train_loss:0.9810531281388604, valid_loss:1.0718558003796814\n",
      "Epoch 45 | train_loss:0.993678678135668, valid_loss:1.0020213647487841\n",
      "Epoch 46 | train_loss:0.9890421602845706, valid_loss:1.0271923086255008\n",
      "Epoch 47 | train_loss:1.0233836366716924, valid_loss:1.0702429854813054\n",
      "Epoch 48 | train_loss:0.9765429755081949, valid_loss:1.0134040621928555\n",
      "Epoch 49 | train_loss:0.9747500916663459, valid_loss:1.0160650832227383\n",
      "Epoch 50 | train_loss:0.9676718274855942, valid_loss:0.9890872180187601\n",
      "Epoch 51 | train_loss:0.9692351013370799, valid_loss:0.9968999233516216\n",
      "Epoch 52 | train_loss:0.9574884909468191, valid_loss:1.05137826776172\n",
      "Epoch 53 | train_loss:0.9901460713881027, valid_loss:1.0022196182248044\n",
      "Epoch 54 | train_loss:0.9666887028441213, valid_loss:1.093860796206085\n",
      "Epoch 55 | train_loss:0.9529845974796372, valid_loss:0.991569494558569\n",
      "Epoch 56 | train_loss:0.9497484784818496, valid_loss:1.0019416767116565\n",
      "Epoch 57 | train_loss:0.973370179562157, valid_loss:0.9929918909376347\n",
      "Epoch 58 | train_loss:0.9723385064042473, valid_loss:1.0184819952881716\n",
      "Epoch 59 | train_loss:0.9780432067370367, valid_loss:1.0117077226118283\n",
      "Epoch 60 | train_loss:0.9910965467843997, valid_loss:1.034825999149908\n",
      "Epoch 61 | train_loss:0.9646479121918333, valid_loss:1.0386517891359046\n",
      "Epoch 62 | train_loss:0.9584545591734726, valid_loss:1.0122735607753004\n",
      "Epoch 63 | train_loss:0.9548430852111615, valid_loss:1.0176174790499806\n",
      "Epoch 64 | train_loss:0.9589410692570577, valid_loss:0.998850114419243\n",
      "Epoch 65 | train_loss:0.9556175863653922, valid_loss:1.0133291438361893\n",
      "Epoch 66 | train_loss:0.9768532679855532, valid_loss:1.0050170762607775\n",
      "Epoch 67 | train_loss:0.967616182540868, valid_loss:1.0313950360650894\n",
      "Epoch 68 | train_loss:0.9598489038203913, valid_loss:0.9972535273373554\n",
      "Epoch 69 | train_loss:0.9608148801040466, valid_loss:1.043056052061511\n",
      "Epoch 70 | train_loss:0.9879846573002815, valid_loss:1.002847636992721\n",
      "Epoch 71 | train_loss:0.9568294331076361, valid_loss:0.98257375118601\n",
      "Epoch 72 | train_loss:1.0223364899847491, valid_loss:0.9999061337320967\n",
      "Epoch 73 | train_loss:0.9540787680486782, valid_loss:1.0075462240350725\n",
      "Epoch 74 | train_loss:0.9518918056506218, valid_loss:0.9958651233885578\n",
      "Epoch 75 | train_loss:0.9555573804041236, valid_loss:0.987931381838925\n",
      "Epoch 76 | train_loss:0.9508128709390282, valid_loss:0.9908446789394867\n",
      "Epoch 77 | train_loss:0.962938488970893, valid_loss:1.0241804912245565\n",
      "Epoch 78 | train_loss:0.970633612300894, valid_loss:0.9939320496816805\n",
      "Epoch 79 | train_loss:0.9460822671767742, valid_loss:1.0933051864915153\n",
      "Epoch 80 | train_loss:0.9687229205669661, valid_loss:1.044544789694041\n",
      "Epoch 81 | train_loss:0.9558276863349234, valid_loss:1.003641935133192\n",
      "Epoch 82 | train_loss:0.976084364877457, valid_loss:1.014399881289973\n",
      "Epoch 83 | train_loss:0.9568694884349322, valid_loss:1.0150303776358423\n",
      "Epoch 84 | train_loss:0.97492619120257, valid_loss:1.0957947474424115\n",
      "Epoch 85 | train_loss:1.025729560963797, valid_loss:1.0082447533499042\n",
      "Epoch 86 | train_loss:0.9681139193811924, valid_loss:1.0168704295119173\n",
      "Epoch 87 | train_loss:0.9548579136397763, valid_loss:0.990502766911023\n",
      "Epoch 88 | train_loss:0.9530315745221638, valid_loss:1.0069735932059174\n",
      "Epoch 89 | train_loss:0.9479785437257421, valid_loss:0.9902734608724795\n",
      "Epoch 90 | train_loss:0.9487963248838385, valid_loss:1.137216441319361\n",
      "Epoch 91 | train_loss:0.9626254757014268, valid_loss:1.0289932742625538\n",
      "Epoch 92 | train_loss:0.9599657129701695, valid_loss:1.052257862239968\n",
      "Epoch 93 | train_loss:0.952325943320577, valid_loss:0.9976613505001932\n",
      "Epoch 94 | train_loss:0.9639589341051344, valid_loss:0.986428999070235\n",
      "Epoch 95 | train_loss:0.9400911207992768, valid_loss:0.9996482812287806\n",
      "Epoch 96 | train_loss:0.9594423672206075, valid_loss:0.9961107722138992\n",
      "Epoch 97 | train_loss:0.974131483089948, valid_loss:1.068242905316227\n",
      "Epoch 98 | train_loss:0.9582760999682532, valid_loss:0.9921846609444882\n",
      "Epoch 99 | train_loss:0.9618134894392423, valid_loss:1.011398775420888\n",
      "Epoch 100 | train_loss:0.9662695746708421, valid_loss:1.0454124701288883\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for epoch in range(100):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_graphs = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(\"cpu\")\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "        #loss = torch.sqrt(criterion(prediction, batch.y[:, target_idx].unsqueeze(1)))\n",
    "        loss = criterion(prediction, batch.y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "        optimizer.step()\n",
    "    train_loss /=  len(train_loader) #損失の平均(batchあたり) #平均を取ってからルート\n",
    "    train_loss = sqrt(train_loss)\n",
    "    \n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    total_graphs = 0\n",
    "    with torch.inference_mode(): # 自動微分無効。torch.no_grad()よりさらに高速化\n",
    "        for batch in valid_loader:\n",
    "            prediction = model(batch)\n",
    "            #loss = torch.sqrt(criterion(prediction, batch.y[:, target_idx].unsqueeze(1)))\n",
    "            loss = criterion(prediction, batch.y)\n",
    "            valid_loss += loss.item()\n",
    "            total_graphs += batch.num_graphs\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_loss = sqrt(valid_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | train_loss:{train_loss}, valid_loss:{valid_loss}\")\n",
    "    #loss_three_50.append({\"Epoch\":epoch + 1 , \"train_loss\":train_loss, \"valid_loss\":valid_loss})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
