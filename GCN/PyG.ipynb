{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.nn import GCNConv, NNConv\n",
    "from torch_geometric.nn.models import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "dataset = QM9(root=\"./QM9\") #Shuffleいらない？\n",
    "#無向グラフの例\n",
    "#edge_index = torch.tensor([[0,1,1,2],[1,0,2,1]], dtype=torch.long) # エッジの定義\n",
    "#x = torch.tensor([[-1],[0],[1]], dtype=torch.float) # ノードの属性\n",
    "#data = Data(x=x, edge_index=edge_index) # コンストラクタ\n",
    "# Data(x=[3, 1], edge_index=[2, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QM9の属性\n",
    "\n",
    "x:ノードの特徴量\n",
    "\n",
    "y:ラベル\n",
    "\n",
    "z:原子番号\n",
    "\n",
    "edge_attr:エッジ特徴量(結合次数)\n",
    "\n",
    "edge_index:エッジリスト\n",
    "\n",
    "pos:3Dグリッドでの各原子の位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.graphcore.ai/posts/getting-started-with-pytorch-geometric-pyg-on-graphcore-ipus\n",
    "\n",
    "# GCN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
    "        self.conv2 = GCNConv(32, 32)\n",
    "        self.linear1 = nn.Linear(16,1)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        #self.conv3 = GCNConv(32, dataset.num_classes) #num_classes:ラベルの数\n",
    "    #バッチノルム(正則化)\n",
    "    def forward(self, data):\n",
    "        x, batch, edge_index, edge_attr = data.x, data.batch, data.edge_index, data.edge_attr\n",
    "        # Dropout:一定割合のノードを不活性化(0になる)させ、過学習を緩和する。pはゼロになるノードの確率で、0.5がデフォルト。\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = torch_geometric.nn.global_add_pool(x, batch) #これが必要やった\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "class GCN_3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
    "        self.conv2 = GCNConv(32, 32)\n",
    "        self.conv3 = GCNConv(32, 32)\n",
    "        self.linear1 = nn.Linear(16,1)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        #self.conv3 = GCNConv(32, dataset.num_classes) #num_classes:ラベルの数\n",
    "    #バッチノルム(正則化)\n",
    "    def forward(self, data):\n",
    "        x, batch, edge_index, edge_attr = data.x, data.batch, data.edge_index, data.edge_attr\n",
    "        # Dropout:一定割合のノードを不活性化(0になる)させ、過学習を緩和する。pはゼロになるノードの確率で、0.5がデフォルト。\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch_geometric.nn.global_add_pool(x, batch) #これが必要やった\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1_net = torch.nn.Sequential(nn.Linear(dataset.num_edge_features, 32),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(32, dataset.num_node_features*32))\n",
    "        self.conv2_net = torch.nn.Sequential(nn.Linear(dataset.num_edge_features, 32),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(32, 32*16))        \n",
    "        self.conv1 = NNConv(dataset.num_node_features, 32, self.conv1_net)\n",
    "        self.conv2 = NNConv(32, 16, self.conv2_net)\n",
    "        self.linear1 = torch.nn.Linear(16, 32)\n",
    "        self.out = nn.Linear(32,1)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = torch_geometric.nn.global_add_pool(x, batch)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの分割(total: 130831)\n",
    "num_train, num_val = int(len(dataset)*0.6), int(len(dataset)*0.2)\n",
    "num_test = len(dataset) - (num_train + num_val)\n",
    "\n",
    "train_set, valid_set, test_set = random_split(dataset, [num_train, num_val, num_test])\n",
    "\n",
    "#Dataloaderの生成\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
    "\n",
    "# GNNの初期化\n",
    "model = GCN_3()\n",
    "#model = GNNModel()\n",
    "# 損失関数\n",
    "criterion = F.mse_loss\n",
    "# Optimizerの初期化\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss:65.4039874082681, valid_loss:18.62198985430231\n",
      "Epoch 2 | train_loss:57.933457065797214, valid_loss:12.317043181037585\n",
      "Epoch 3 | train_loss:53.82730070268863, valid_loss:13.697528622156096\n",
      "Epoch 4 | train_loss:50.657058423137435, valid_loss:13.777025634297116\n",
      "Epoch 5 | train_loss:47.89562332669134, valid_loss:14.104269056742627\n",
      "Epoch 6 | train_loss:45.96767395948817, valid_loss:13.994373593543704\n",
      "Epoch 7 | train_loss:43.97539488080315, valid_loss:14.786800212294732\n",
      "Epoch 8 | train_loss:43.123820455739576, valid_loss:23.397368051810307\n",
      "Epoch 9 | train_loss:41.71788068769881, valid_loss:17.344646799014814\n",
      "Epoch 10 | train_loss:41.21392678059878, valid_loss:15.739677071111618\n",
      "Epoch 11 | train_loss:40.61787937327033, valid_loss:16.48979098962544\n",
      "Epoch 12 | train_loss:40.34612042065677, valid_loss:18.066754609918384\n",
      "Epoch 13 | train_loss:40.06238893775574, valid_loss:16.677697632402555\n",
      "Epoch 14 | train_loss:39.868636586507, valid_loss:18.20998824153071\n",
      "Epoch 15 | train_loss:39.56295078622065, valid_loss:18.229286571728032\n",
      "Epoch 16 | train_loss:39.577177330066505, valid_loss:16.243622823928103\n",
      "Epoch 17 | train_loss:39.491938130245764, valid_loss:17.12423228568986\n",
      "Epoch 18 | train_loss:39.213323062119926, valid_loss:17.194797159388497\n",
      "Epoch 19 | train_loss:39.11652278294955, valid_loss:21.42493421529265\n",
      "Epoch 20 | train_loss:39.073480196018195, valid_loss:16.638138267507674\n"
     ]
    }
   ],
   "source": [
    "# 学習したいラベルのインデックス位置\n",
    "target_idx = 1\n",
    "\n",
    "for epoch in range(50):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total_graphs = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(\"cpu\")\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(batch)\n",
    "        loss = torch.sqrt(criterion(prediction, batch.y[:, target_idx].unsqueeze(1)))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "        optimizer.step()\n",
    "    train_loss /= math.sqrt(total_graphs) #損失の平均\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    total_graphs = 0\n",
    "    with torch.inference_mode(): # 自動微分無効。torch.no_grad()よりさらに高速化\n",
    "        for batch in valid_loader:\n",
    "            prediction = model(batch)\n",
    "            loss = torch.sqrt(criterion(prediction, batch.y[:, target_idx].unsqueeze(1)))\n",
    "            valid_loss += loss.item()\n",
    "            total_graphs += batch.num_graphs\n",
    "    valid_loss /= math.sqrt(total_graphs)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | train_loss:{train_loss}, valid_loss:{valid_loss}\")\n",
    "    #なんかvalid_lossのほうが小さい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333432674408"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(torch.Tensor([1,1,1]),torch.Tensor([1,1,2])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8560e-35])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lossの計算がおかしい　batchかグラフが多いほど誤差が大きくなるようになってる？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QM9(130831)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.num_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.97473512632437"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqrt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sqrt\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sqrt' is not defined"
     ]
    }
   ],
   "source": [
    "sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([82.1755, 81.4774, 58.7662, 66.0292, 73.3747, 88.9727, 74.6518, 71.2338,\n",
       "        74.3432, 69.8561, 79.1986, 86.8198, 62.3695, 73.2541, 77.7144, 81.5433,\n",
       "        67.5248, 73.8379, 74.6417, 78.3584, 73.6930, 74.0313, 72.8392, 81.3193,\n",
       "        59.6216, 81.7011, 75.3242, 62.2873, 81.1038, 69.8394, 61.3492, 81.1513],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:, target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([78.9400, 68.8500, 79.3400, 85.9600, 77.0400, 80.6700, 64.5700, 78.6200,\n",
       "        69.5200, 81.2700, 70.3800, 76.9300, 70.3300, 62.9300, 76.5500, 65.3100,\n",
       "        89.1800, 82.7900, 80.0900, 75.8200, 50.7900, 85.8600, 85.0100, 61.2400,\n",
       "        87.6700, 94.2200, 76.3200, 68.6600, 75.3300, 70.3300, 72.0200, 76.4000])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.y[:, target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # 評価開始\n",
    "predictions = []\n",
    "real = []\n",
    "for batch in test_loader:\n",
    "    output = model(batch.to(\"cpu\"))\n",
    "    predictions.append(output.detach().cpu().numpy())\n",
    "    real.append(batch.y[:,target_idx].detach().cpu().numpy())\n",
    "real = np.concatenate(real)\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "plt.scatter(real, predictions)\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('real')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Your Own Datasets\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
    "\n",
    "https://qiita.com/maskot1977/items/4aa6322459eb3a78955f\n",
    "\n",
    "\n",
    "Datasets\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html\n",
    "\n",
    "\n",
    "TORCH.NN.FUNCTIONAL\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.functional.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# エタンのグラフ構造の作成\n",
    "mol = Chem.MolFromSmiles(\"CC\")\n",
    "mol = Chem.AddHs(mol)\n",
    "atoms = mol.GetAtoms()\n",
    "bonds = mol.GetBonds()\n",
    "bonds[0].GetEndAtomIdx()\n",
    "\n",
    "edge_list = []\n",
    "for bond in bonds:\n",
    "    edge_list.append([bond.GetBeginAtomIdx(),bond.GetEndAtomIdx()])\n",
    "    edge_list.append([bond.GetEndAtomIdx(),bond.GetBeginAtomIdx()])\n",
    "edge_index = torch.tensor(edge_list) #エッジのリスト作成\n",
    "x = torch.tensor([[atom.GetAtomicNum()] for atom in atoms]) # 原子番号\n",
    "\n",
    "edge_attr = []\n",
    "for bond in bonds:\n",
    "    edge_attr.append([])\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ構造の可視化\n",
    "import networkx\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "from IPython.display import SVG, display\n",
    "data = dataset[4921]\n",
    "nxg = to_networkx(data)\n",
    "\n",
    "pagerank = networkx.pagerank(nxg) #pagerankはノードの中心性(重要性の指標)\n",
    "pagerank_max = np.array(list(pagerank.values())).max()\n",
    "\n",
    "#可視化する時のノード位置\n",
    "draw_position = networkx.spring_layout(nxg,seed=0)\n",
    "\n",
    "# 色指定\n",
    "color_map = plt.get_cmap(\"tab10\")\n",
    "labels = data.x.numpy()\n",
    "colors = [color_map(i) for i in labels]\n",
    "\n",
    "svg = SVG(networkx.nx_agraph.to_agraph(nxg).draw(prog='fdp', format='svg'))\n",
    "display(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習したいラベルのインデックス位置\n",
    "target_idx = 1\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train() #訓練モード\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y[:, target_idx].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_avg_loss = epoch_loss / total_graphs\n",
    "    val_loss = 0\n",
    "    total_graphs = 0\n",
    "    model.eval()\n",
    "    for batch in valid_loader:\n",
    "        output = model(batch)\n",
    "        loss = criterion(output,batch.y[:, target_idx].unsqueeze(1)) #平方根で比較\n",
    "        val_loss += loss.item()\n",
    "        total_graphs += batch.num_graphs\n",
    "    \n",
    "    val_avg_loss = val_loss / total_graphs\n",
    "    print(f\"Epochs: {i} | epoch avg. loss: {train_avg_loss:.2f} | validation avg. loss: {val_avg_loss:.2f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
