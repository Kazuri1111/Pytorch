import torch
from torch import nn, optim
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

device = "cpu"
iris = datasets.load_iris()
X = iris.data.astype(np.float32)
Y = iris.target.astype(np.int64)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)
X_train, X_test, Y_train, Y_test = (
    torch.from_numpy(X_train).to(device),
    torch.from_numpy(X_test).to(device),
    torch.from_numpy(Y_train).to(device),
    torch.from_numpy(Y_test).to(device),
)


class model_iris(nn.Module):
    def __init__(self):
        super(model_iris, self).__init__()

        self.model_info = nn.ModuleList(
            [
                nn.Linear(4, 6),
                nn.Sigmoid(),
                nn.Linear(6, 3),
            ]
        )

    def forward(self, x):
        for i in range(len(self.model_info)):
            x = self.model_info[i](x)
        return x


rates = []
# training
for repeat in range(10, 2100, 50):
    model = model_iris().to(device)
    optimizer = optim.SGD(model.parameters(), lr=0.05)
    criterion = nn.CrossEntropyLoss()
    for epoch in range(repeat):
        ex_var = X_train
        target = Y_train
        output = model(ex_var)
        loss = criterion(output, target)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        model.eval()
        with torch.no_grad():
		pred_model = model(X_test)
		pred_result = torch.argmax(pred_model, 1)
		rate = round(((Y_test == pred_result).sum() / len(pred_result)).item(), 3)
		rates.append((repeat, rates))
		print(f"{repeat} completed.")

x = [i[0] for i in rates]
y = [i[1] for i in rates]
plt.plot(x, y)
plt.show()
